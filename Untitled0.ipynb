{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yIFWhFlEkLdX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "19ayGjjgmAPs",
        "outputId": "13467981-1509-459f-c6df-15f20aba328f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp38-cp38-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.0\n",
            "    Uninstalling torchtext-0.14.0:\n",
            "      Successfully uninstalled torchtext-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy import data, datasets \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "training_epochs = 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Se4NdwmC_a",
        "outputId": "2db4e036-cd7b-4701-94f7-6d1666bbcab9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMDB Dataset\n",
        "\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.Field(sequential=False, batch_first=True)\n",
        "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "TEXT.build_vocab(trainset, min_freq=5)  # TEXT 데이터를 기반으로 Vocab 생성\n",
        "LABEL.build_vocab(trainset)             # LABEL 데이터를 기반으로 Vocab 생성\n",
        "\n",
        "# 학습용 데이터를 학습셋 80% 검증셋 20% 로 나누기\n",
        "trainset, valset = trainset.split(split_ratio=0.8)\n",
        "\n",
        "# 매 배치마다 비슷한 길이에 맞춰 줄 수 있도록 iterator 정의\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "        (trainset, valset, testset), batch_size=batch_size,\n",
        "        shuffle=True, repeat=False)\n",
        "\n",
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes = 2                           # Positive, Negative Class가 두 개\n",
        "\n",
        "print(\"[TrainSet]: %d [ValSet]: %d [TestSet]: %d [Vocab]: %d [Classes] %d\"\n",
        "      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC1l5Al7qOw3",
        "outputId": "856c7124-0efe-4653-9b9b-89927e5db68b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 22.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TrainSet]: 20000 [ValSet]: 5000 [TestSet]: 25000 [Vocab]: 46159 [Classes] 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicGRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(BasicGRU, self).__init__()          \n",
        "        self.n_layers = n_layers \n",
        "\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True)\n",
        "        \n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.embed(x)\n",
        "        x, _ = self.gru(x)  \n",
        "        h_t = x[:,-1,:]\n",
        "        self.dropout(h_t)\n",
        "\n",
        "        out = self.out(h_t)  \n",
        "        return out"
      ],
      "metadata": {
        "id": "F4Gq9Jr2qSeX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n",
        "\n",
        "# cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  for batch in train_iter:\n",
        "    X, Y = batch.text.to(device), batch.label.to(device)\n",
        "    Y.data.sub_(1)\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    avg_cost += cost / batch_size\n",
        "  print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
        "print('Learning Finished!')\n",
        "\n",
        "# Model Save\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/AI_Final/model_s1.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Cmgg60Tqi9h",
        "outputId": "993fcda9-9a7b-4fb5-b8b1-4d4a34b1522d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 3.42060065\n",
            "[Epoch:    2] cost = 3.39446473\n",
            "[Epoch:    3] cost = 3.39399147\n",
            "[Epoch:    4] cost = 3.21248937\n",
            "[Epoch:    5] cost = 1.98488772\n",
            "Learning Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model load\n",
        "model_new = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n",
        "model_new.load_state_dict(torch.load('/content/drive/MyDrive/AI_Final/model_s1.pt'))\n",
        "\n",
        "corrects = 0\n",
        "for batch in val_iter:\n",
        "  x,y = batch.text.to(device), batch.label.to(device)\n",
        "  y.data.sub_(1)\n",
        "  hypothesis = model_new(x)\n",
        "  corrects += (hypothesis.max(1)[1].view(y.size()).data == y.data).sum() \n",
        "\n",
        "print('accuracy = ', corrects/len(val_iter.dataset)*100.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdo-qFpWs41j",
        "outputId": "652879d3-d7ec-4f86-d41f-a996bf42a4af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy =  tensor(83.8000, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = testset[2].text\n",
        "print(input_text)\n",
        "print(TEXT.vocab[input_text[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7T3VHCpuQsp",
        "outputId": "618d4901-c6ed-4910-df8e-0603974524a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['when,', 'oh,', 'when', 'will', 'someone', 'like', 'anchor', 'bay', 'or', 'blue', 'underground', 'release', 'this', 'on', 'widescreen', 'dvd???', 'le', 'orme,', 'which', 'i', 'only', 'know', 'because', 'of', 'my', 'rare/vintage', 'video', 'collecting', 'habit,', 'is', 'a', 'film', 'in', 'my', 'collection', 'that', 'i', 'would', 'not', 'only', 'sit', 'through,', 'but', 'actually', 'enjoy', 'watching.', 'the', 'fact', 'that', 'klaus', 'kinski', 'is', 'top', 'billed,', 'but', 'is', 'only', 'in', 'small', 'parts', 'of', 'the', 'film,', 'means', 'little', 'to', 'me.', '(though', 'several', 'comments', 'expressed', 'disappointment', 'in', 'his', 'rather', 'limited', 'screen', 'time.)', 'i', 'cannot', 'say', 'that', 'this', 'is', 'a', 'good', 'horror', 'film,', 'a', 'good', 'mystery,', 'a', 'sci-fi', 'epic', 'or', 'anything', 'of', 'that', 'nature.', 'it', 'is', 'simply', 'unclassifiable', 'in', 'the', '\"genre\"', 'sense', 'of', 'things.', 'it', 'is', 'more', 'like', 'a', 'confusing,', 'frightening', '(though', 'not', 'particularly', 'violent', 'or', 'bloody)', 'dream,', 'filled', 'with', 'great', 'visuals', 'and', 'mystery.', 'it', 'relies', 'on', 'visuals', 'and', 'emotion,', 'much', 'like', \"bava's\", '\"lisa', 'and', 'the', 'devil\".', 'both', 'films', 'are', 'beautiful', 'in', 'almost', 'every', 'sense,', 'but', 'almost', 'impossible', 'to', 'describe', 'in', 'a', 'logical', 'manner;', 'they', 'both', 'occur', 'in', 'such', 'a', 'dream-like', 'atmosphere.', \"don't\", 'be', 'deterred', 'by', 'force', \"video's\", 'synopsis', 'on', 'the', 'back', 'cover.', 'it', 'is', 'infinitely', 'more', 'complex', 'and', 'intriguing', 'than', 'that.', 'though', 'force', \"video's\", 'release', 'from', '1986', '(the', 'only', 'one', 'in', 'the', 'us,', 'that', 'i', 'know', 'of)', 'is', 'cropped', 'to', 'full-screen', 'on', 'tape,', 'even', 'in', 'that', 'format', 'it', 'is', 'still', 'great.', 'releasing', 'it', 'remastered', 'and/or', 'letterboxed', 'would', 'make', 'it', 'magnificent', '(hint,', 'hint...', 'dvd', 'companies).']\n",
            "7325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = testset[3].text\n",
        "import numpy as np\n",
        "\n",
        "temp = []\n",
        "\n",
        "for i in testset[3].text:\n",
        "  temp.append(TEXT.vocab[i])\n",
        "print(temp)\n",
        "\n",
        "X_t = torch.LongTensor(np.array(temp))\n",
        "X_t = X_t.unsqueeze(dim=0)\n",
        "hypothesis = model_new(X_t.to(device))\n",
        "\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "quFB1_pRuXgz",
        "outputId": "5b4d9fb2-9efb-4846-986b-9df07a3bf9dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b13f513e73ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'testset' is not defined"
          ]
        }
      ]
    }
  ]
}